{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11170579,"sourceType":"datasetVersion","datasetId":6971220},{"sourceId":12424881,"sourceType":"datasetVersion","datasetId":7836856},{"sourceId":12481621,"sourceType":"datasetVersion","datasetId":7875585},{"sourceId":12481942,"sourceType":"datasetVersion","datasetId":7875797}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-16T15:27:49.601616Z"},"_kg_hide-input":true,"_kg_hide-output":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q albumentations\n!pip install -q segmentation-models-pytorch\n!pip install -q exifread\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport segmentation_models_pytorch as smp\n\nimport torch.nn as nn\nimport torch.optim as optim\n\nfrom tqdm import tqdm\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\n\nfrom scipy.ndimage import center_of_mass\n\nimport folium\n\nimport exifread\n\nimport glob, cv2, torch\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Set Dataset Paths","metadata":{}},{"cell_type":"code","source":"# Set image and mask directories\ntrain_image_dir = \"/kaggle/input/deepcrack/DeepCrack-master/dataset/DeepCrack/train_img\"\ntrain_mask_dir  = \"/kaggle/input/deepcrack/DeepCrack-master/dataset/DeepCrack/train_lab\"\n\ntest_image_dir  = \"/kaggle/input/deepcrack/DeepCrack-master/dataset/DeepCrack/test_img\"\ntest_mask_dir   = \"/kaggle/input/deepcrack/DeepCrack-master/dataset/DeepCrack/test_lab\"\n\n\n\n# Get all image names\nall_images = sorted(os.listdir(train_image_dir))\n\n# Train/val split\ntrain_imgs, val_imgs = train_test_split(all_images, test_size=0.2, random_state=42)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\nuav_image_dir = \"/kaggle/input/uav-based-crack-detection-dataset/UAV-based crack dataset used for segmentation/image\"\nsample_img_path = os.path.join(uav_image_dir, sorted(os.listdir(uav_image_dir))[0])\n\nwith open(sample_img_path, 'rb') as f:\n    tags = exifread.process_file(f)\n    gps_tags = {tag: val for tag, val in tags.items() if \"GPS\" in tag}\n    print(\"Extracted GPS tags:\")\n    print(gps_tags)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" Create Dataset Class","metadata":{}},{"cell_type":"code","source":"# class DeepCrackDataset(Dataset):\n#     def __init__(self, image_dir, mask_dir, transform=None):\n#         self.image_dir = image_dir\n#         self.mask_dir = mask_dir\n#         self.transform = transform\n#         self.images = sorted(os.listdir(image_dir))  # ensure consistent order\n\n#     def __len__(self):\n#         return len(self.images)\n\n#     def __getitem__(self, idx):\n#         img_name = self.images[idx]\n#         mask_name = img_name.replace(\".jpg\", \".png\")  # match .png mask to .jpg image\n\n#         img_path = os.path.join(self.image_dir, img_name)\n#         mask_path = os.path.join(self.mask_dir, mask_name)\n\n#         # Load and preprocess\n#         image = cv2.imread(img_path)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n#         mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n#         mask = mask / 255.0  # normalize binary mask\n#         mask = torch.tensor(mask).unsqueeze(0).float()\n\n#         # Normalize image to [0, 1]\n#         image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n\n#         return image, mask\n\n\n\nclass DeepCrackDataset(Dataset):\n    def __init__(self, image_dir, mask_dir, image_list, transform=None):\n        self.image_dir = image_dir\n        self.mask_dir = mask_dir\n        self.images = image_list\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_name = self.images[idx]\n        mask_name = img_name.replace(\".jpg\", \".png\")\n\n        img_path = os.path.join(self.image_dir, img_name)\n        mask_path = os.path.join(self.mask_dir, mask_name)\n\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE) / 255.0\n        mask = torch.tensor(mask).unsqueeze(0).float()\n\n        image = torch.tensor(image).permute(2, 0, 1).float() / 255.0\n\n        return image, mask\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Metric Functions","metadata":{}},{"cell_type":"code","source":"def dice_coeff(pred, target, threshold=0.5):\n    pred = torch.sigmoid(pred) > threshold\n    target = target > 0.5\n    intersection = (pred & target).float().sum((1, 2, 3))\n    union = pred.float().sum((1, 2, 3)) + target.float().sum((1, 2, 3))\n    dice = (2. * intersection + 1e-7) / (union + 1e-7)\n    return dice.mean().item()\n\ndef iou_score(pred, target, threshold=0.5):\n    pred = torch.sigmoid(pred) > threshold\n    target = target > 0.5\n    intersection = (pred & target).float().sum((1, 2, 3))\n    union = (pred | target).float().sum((1, 2, 3))\n    iou = (intersection + 1e-7) / (union + 1e-7)\n    return iou.mean().item()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train_dataset = DeepCrackDataset(train_image_dir, train_mask_dir)\n# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n\ntrain_dataset = DeepCrackDataset(train_image_dir, train_mask_dir, train_imgs)\nval_dataset   = DeepCrackDataset(train_image_dir, train_mask_dir, val_imgs)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nval_loader   = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images, masks = next(iter(train_loader))\nplt.figure(figsize=(10, 5))\nplt.subplot(1, 2, 1)\nplt.imshow(images[0].permute(1, 2, 0))\nplt.title(\"Image\")\nplt.subplot(1, 2, 2)\nplt.imshow(masks[0][0], cmap='gray')\nplt.title(\"Mask\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" Define U-Net Model","metadata":{}},{"cell_type":"code","source":"# Define model with a pretrained encoder\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",        # Pretrained backbone\n    encoder_weights=\"imagenet\",     # Use weights trained on ImageNet\n    in_channels=3,                  # RGB input\n    classes=1,                      # Binary mask output\n    activation=None                 # We'll apply sigmoid manually\n).cuda()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":" Set Up Loss, Optimizer, Metrics","metadata":{}},{"cell_type":"code","source":"\n\nloss_fn = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\n\nscheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Training Loop","metadata":{}},{"cell_type":"code","source":"num_epochs = 50\n\n\nfor epoch in range(num_epochs):\n    model.train()\n    total_loss = 0\n    total_dice = 0\n    total_iou = 0\n\n    for images, masks in tqdm(train_loader):\n        images, masks = images.cuda(), masks.cuda()\n\n        preds = model(images)\n        loss = loss_fn(preds, masks)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        # Metrics\n        total_loss += loss.item()\n        total_dice += dice_coeff(preds, masks)\n        total_iou += iou_score(preds, masks)\n\n    avg_loss = total_loss / len(train_loader)\n    avg_dice = total_dice / len(train_loader)\n    avg_iou = total_iou / len(train_loader)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | Dice: {avg_dice:.4f} | IoU: {avg_iou:.4f}\")\n\n    scheduler.step(avg_loss)  # uses avg_loss to decide whether to reduce LR\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"unet_deepcrack_best.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\n\n# Load one sample from the validation dataset\nimg, true_mask = val_dataset[0]\nimg_input = img.unsqueeze(0).cuda()\n\nwith torch.no_grad():\n    pred_mask = model(img_input)\n    pred_mask = torch.sigmoid(pred_mask).squeeze().cpu().numpy()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(15, 4))\n\nplt.subplot(1, 3, 1)\nplt.imshow(img.permute(1, 2, 0))\nplt.title(\"Validation Image\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(true_mask.squeeze(), cmap='gray')\nplt.title(\"Ground Truth Mask\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(pred_mask > 0.5, cmap='gray')\nplt.title(\"Predicted Mask\")\n\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"[](http://)","metadata":{}},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom PIL.ExifTags import TAGS, GPSTAGS\n\ndef extract_gps_from_exif(image_path):\n    try:\n        image = Image.open(image_path)\n        exif_data = image._getexif()\n        if not exif_data:\n            return None\n\n        gps_info = {}\n        for tag, value in exif_data.items():\n            tag_name = TAGS.get(tag)\n            if tag_name == \"GPSInfo\":\n                for t in value:\n                    sub_tag = GPSTAGS.get(t, t)\n                    gps_info[sub_tag] = value[t]\n                return gps_info\n    except Exception as e:\n        print(f\"Error reading {image_path}: {e}\")\n    return None\n\n# Change this path to point to your dataset\nfolder_path = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image\"\n\nfor filename in os.listdir(folder_path):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        gps_data = extract_gps_from_exif(os.path.join(folder_path, filename))\n        if gps_data:\n            print(f\"✅ {filename} GPS Data: {gps_data}\")\n        else:\n            print(f\"❌ {filename} has no GPS metadata.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import exifread\n\ndef extract_gps_from_image(image_path):\n    with open(image_path, 'rb') as f:\n        tags = exifread.process_file(f)\n        gps_tags = {tag: tags[tag] for tag in tags if \"GPS\" in tag}\n        return gps_tags\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import glob\n\nimage_dir = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image/\"\ngps_lookup = {}\n\nfor img_path in glob.glob(os.path.join(image_dir, \"*.jpg\")):\n    gps = extract_gps_from_image(img_path)\n    if gps:\n        gps_lookup[os.path.basename(img_path)] = gps\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dms_to_decimal(dms, ref):\n    degrees = float(dms.values[0].num) / dms.values[0].den\n    minutes = float(dms.values[1].num) / dms.values[1].den\n    seconds = float(dms.values[2].num) / dms.values[2].den\n    decimal = degrees + (minutes / 60.0) + (seconds / 3600.0)\n    return -decimal if ref in ['S', 'W'] else decimal\n\ndef convert_to_degrees(value):\n    \"\"\"Helper function to convert EXIF DMS to decimal.\"\"\"\n    d, m, s = value\n    return d + (m / 60.0) + (s / 3600.0)\n\ndef get_decimal_coords(gps_data):\n    \"\"\"Extracts decimal latitude and longitude from GPS EXIF.\"\"\"\n    try:\n        lat = convert_to_degrees(gps_data['GPSLatitude'])\n        if gps_data['GPSLatitudeRef'] != 'N':\n            lat = -lat\n        lon = convert_to_degrees(gps_data['GPSLongitude'])\n        if gps_data['GPSLongitudeRef'] != 'E':\n            lon = -lon\n        return lat, lon\n    except:\n        return None, None\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import folium\n\nfolder_path = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image\"\nmap_center = [36.35, 59.50]  # Use approximate center for initializing the map\n\nm = folium.Map(location=map_center, zoom_start=13)\n\nfor filename in os.listdir(folder_path):\n    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n        image_path = os.path.join(folder_path, filename)\n        gps_data = extract_gps_from_exif(image_path)\n        if gps_data:\n            lat, lon = get_decimal_coords(gps_data)\n            if lat and lon:\n                folium.Marker(\n                    location=[lat, lon],\n                    popup=f\"Crack Detected: {filename}\",\n                    icon=folium.Icon(color=\"red\", icon=\"wrench\", prefix=\"fa\")\n                ).add_to(m)\n            else:\n                print(f\"⚠️ Skipped (missing lat/lon): {filename}\")\n        else:\n            print(f\"❌ No GPS metadata: {filename}\")\n\nm.save(\"sut_crack_map.html\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"sut_img_dir = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image\"\n\nsut_images = sorted([f for f in os.listdir(sut_img_dir) if f.endswith(\".jpg\")])\nsut_predictions = []\n\nfor img_name in sut_images[:100]:  # limit for now\n    img_path = os.path.join(sut_img_dir, img_name)\n    img = cv2.imread(img_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_tensor = torch.tensor(img).permute(2, 0, 1).unsqueeze(0).float().cuda() / 255.0\n\n    with torch.no_grad():\n        pred = model(img_tensor)\n        pred = torch.sigmoid(pred).squeeze().cpu().numpy()\n    \n    sut_predictions.append((img_name, pred))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nfrom PIL.ExifTags import TAGS, GPSTAGS\n\ndef get_decimal_from_dms(dms, ref):\n    degrees, minutes, seconds = dms\n    decimal = degrees + minutes / 60 + seconds / 3600\n    if ref in ['S', 'W']:\n        decimal = -decimal\n    return decimal\n\ndef get_image_gps(image_path):\n    image = Image.open(image_path)\n    exif_data = image._getexif()\n    if not exif_data:\n        return None\n    for tag, val in exif_data.items():\n        if TAGS.get(tag) == \"GPSInfo\":\n            gps_info = {GPSTAGS.get(t, t): val[t] for t in val}\n            lat = get_decimal_from_dms(gps_info['GPSLatitude'], gps_info['GPSLatitudeRef'])\n            lon = get_decimal_from_dms(gps_info['GPSLongitude'], gps_info['GPSLongitudeRef'])\n            return (lat, lon)\n    return None\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import folium\nfrom scipy.ndimage import center_of_mass\n\nm = folium.Map(location=[36.3, 59.5], zoom_start=13)\n\nfor img_name, pred_mask in sut_predictions:\n    if pred_mask.max() < 0.5:  # skip if no crack detected\n        continue\n\n    # Calculate centroid of predicted crack\n    pred_binary = (pred_mask > 0.5).astype(np.uint8)\n    if pred_binary.sum() == 0:\n        continue\n    y, x = center_of_mass(pred_binary)\n\n    gps = get_image_gps(os.path.join(sut_img_dir, img_name))\n    if gps:\n        folium.Marker(\n            location=gps,\n            popup=img_name,\n            icon=folium.Icon(color='red', icon='road')\n        ).add_to(m)\n\nm.save(\"sut_crack_inference_map.html\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import torch\nimport segmentation_models_pytorch as smp\n\n# Define the model architecture\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",\n    encoder_weights=\"imagenet\",\n    in_channels=3,\n    classes=1,\n    activation=None\n).cuda()\n\n# Load trained weights\nmodel.load_state_dict(torch.load(\"/kaggle/working/unet_deepcrack_best.pth\"))\nmodel.eval()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nfrom torchvision import transforms\n\n# Preprocessing: resize to match training size, normalize\npreprocess = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor()\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom PIL.ExifTags import TAGS, GPSTAGS\nfrom PIL import Image as PILImage\nfrom scipy.ndimage import center_of_mass\nimport folium\n\n# Path to SUT-Crack UAV image folder\nsut_image_dir = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image\"\n\n# Function to extract GPS from EXIF\ndef get_gps(img_path):\n    img = PILImage.open(img_path)\n    exif = img._getexif()\n    if not exif: return None\n    gps_info = {}\n    for tag, value in exif.items():\n        if TAGS.get(tag) == \"GPSInfo\":\n            for t in value:\n                gps_info[GPSTAGS.get(t, t)] = value[t]\n            break\n    if not gps_info: return None\n\n    def to_deg(dms):\n        d, m, s = dms\n        return d + m / 60.0 + s / 3600.0\n\n    lat = to_deg(gps_info['GPSLatitude'])\n    if gps_info['GPSLatitudeRef'] != 'N': lat *= -1\n    lon = to_deg(gps_info['GPSLongitude'])\n    if gps_info['GPSLongitudeRef'] != 'E': lon *= -1\n    return (lat, lon)\n\n# Initialize map\ncrack_map = folium.Map(location=[36.2, 59.3], zoom_start=14)\n\n# Loop through images\nfor fname in sorted(os.listdir(sut_image_dir))[:100]:  # sample limit\n    if not fname.lower().endswith(\".jpg\"): continue\n    img_path = os.path.join(sut_image_dir, fname)\n    \n    gps = get_gps(img_path)\n    if not gps: continue\n    \n    # Load and preprocess\n    image = PILImage.open(img_path).convert(\"RGB\")\n    image_resized = preprocess(image).unsqueeze(0).cuda()\n\n    # Predict\n    with torch.no_grad():\n        pred = torch.sigmoid(model(image_resized)).squeeze().cpu().numpy()\n        binary_mask = (pred > 0.5).astype(np.uint8)\n\n    # Find center of mass of crack region\n    if binary_mask.sum() == 0: continue  # no crack found\n    cy, cx = center_of_mass(binary_mask)\n\n    # Add marker to map\n    folium.Marker(\n        location=gps,\n        popup=folium.Popup(f\"<b>{fname}</b>\", max_width=200),\n        icon=folium.Icon(color=\"red\", icon=\"wrench\", prefix=\"fa\")\n    ).add_to(crack_map)\n\n# Save map\ncrack_map.save(\"/kaggle/working/sut_crack_inference_map.html\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nfrom torchvision import transforms\n\ndef preprocess_image(image_path, target_size=(512, 512)):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    resized = cv2.resize(image, target_size)\n    tensor = transforms.ToTensor()(resized)\n    return tensor.unsqueeze(0), image  # model input, original RGB\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\ndef load_model():\n    model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1)\n    model.load_state_dict(torch.load(\"/kaggle/working/unet_deepcrack_best.pth\", map_location=torch.device('cpu')))\n    model.eval()\n    return model\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_crack_mask(model, image_tensor, threshold=0.5):\n    with torch.no_grad():\n        output = model(image_tensor)\n        mask = torch.sigmoid(output).squeeze().numpy()\n        binary_mask = (mask > threshold).astype(np.uint8)\n    return binary_mask\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def visualize_result(original, mask):\n    mask_resized = cv2.resize(mask, (original.shape[1], original.shape[0]))\n    overlay = original.copy()\n    overlay[mask_resized == 1] = [255, 0, 0]  # mark damage in red\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.title(\"Original\")\n    plt.imshow(original)\n    plt.subplot(1, 2, 2)\n    plt.title(\"Predicted Mask\")\n    plt.imshow(overlay)\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_path = \"/kaggle/input/uav-based-crack-detection-dataset/UAV-based crack dataset used for segmentation/image/DJI0090.png\"\ntensor_input, original_img = preprocess_image(img_path)\nmodel = load_model()\npredicted_mask = predict_crack_mask(model, tensor_input)\nvisualize_result(original_img, predicted_mask)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import exifread\n\ndef extract_gps_from_exif(image_path):\n    with open(image_path, 'rb') as f:\n        tags = exifread.process_file(f)\n\n    def get_decimal_from_dms(dms, ref):\n        degrees = dms.values[0].num / dms.values[0].den\n        minutes = dms.values[1].num / dms.values[1].den\n        seconds = dms.values[2].num / dms.values[2].den\n        decimal = degrees + minutes/60 + seconds/3600\n        if ref in ['S', 'W']:\n            decimal *= -1\n        return decimal\n\n    try:\n        lat = get_decimal_from_dms(tags['GPS GPSLatitude'], tags['GPS GPSLatitudeRef'])\n        lon = get_decimal_from_dms(tags['GPS GPSLongitude'], tags['GPS GPSLongitudeRef'])\n        return lat, lon\n    except KeyError:\n        print(\"GPS data not found.\")\n        return None, None\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.ndimage import center_of_mass\n\ndef get_crack_centroid(mask):\n    if np.sum(mask) == 0:\n        return None\n    y, x = center_of_mass(mask)\n    return int(x), int(y)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import folium\n\ndef plot_crack_on_map(lat, lon, save_path=\"sut_crack_inference_map.html\"):\n    m = folium.Map(location=[lat, lon], zoom_start=20)\n    folium.Marker(location=[lat, lon], popup=\"Detected Crack\").add_to(m)\n    m.save(save_path)\n    print(f\"Map saved to {save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import base64\nfrom io import BytesIO\nfrom PIL import Image\n\ndef plot_crack_with_preview(lat, lon, original_img, mask, save_path=\"sut_crack_single_map.html\"):\n    # Resize and overlay the mask\n    mask_resized = cv2.resize(mask, (original_img.shape[1], original_img.shape[0]))\n    overlay = original_img.copy()\n    overlay[mask_resized == 1] = [255, 0, 0]\n\n    # Convert to PNG for popup\n    img = Image.fromarray(overlay)\n    buffer = BytesIO()\n    img.save(buffer, format=\"PNG\")\n    encoded = base64.b64encode(buffer.getvalue()).decode()\n\n    m = folium.Map(location=[lat, lon], zoom_start=20)\n    html = f'<img src=\"data:image/png;base64,{encoded}\" width=\"300\">'\n    popup = folium.Popup(html, max_width=300)\n    folium.Marker([lat, lon], popup=popup, icon=folium.Icon(color=\"red\")).add_to(m)\n    m.save(save_path)\n    print(f\"✅ Map saved to: {save_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_path = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image/100.jpg\"\n\n# Inference\ntensor_input, original_img = preprocess_image(img_path)\nmodel = load_model()\npred_mask = predict_crack_mask(model, tensor_input)\n\n# ✅ Show crack detection result\nvisualize_result(original_img, pred_mask)\n\n# GPS Tagging and Mapping\nlat, lon = extract_gps_from_exif(img_path)\nif lat and lon:\n    plot_crack_on_map(lat, lon)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def preprocess_image(image_path, target_size=(512, 512)):\n    image = cv2.imread(image_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    resized = cv2.resize(image, target_size)\n    tensor = transforms.ToTensor()(resized)\n    return tensor.unsqueeze(0), image\n\ndef load_model():\n    model = smp.Unet(encoder_name=\"resnet34\", encoder_weights=\"imagenet\", in_channels=3, classes=1)\n    model.load_state_dict(torch.load(\"/kaggle/working/unet_deepcrack_best.pth\", map_location=torch.device('cpu')))\n    model.eval()\n    return model\n\ndef predict_crack_mask(model, image_tensor, threshold=0.5):\n    with torch.no_grad():\n        output = model(image_tensor)\n        mask = torch.sigmoid(output).squeeze().numpy()\n        return (mask > threshold).astype(np.uint8)\n\ndef visualize_result(original, mask):\n    mask_resized = cv2.resize(mask, (original.shape[1], original.shape[0]))\n    overlay = original.copy()\n    overlay[mask_resized == 1] = [255, 0, 0]\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.title(\"Original\")\n    plt.imshow(original)\n    plt.subplot(1, 2, 2)\n    plt.title(\"Predicted Mask\")\n    plt.imshow(overlay)\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_gps_from_exif(image_path):\n    with open(image_path, 'rb') as f:\n        tags = exifread.process_file(f)\n\n    def get_decimal_from_dms(dms, ref):\n        degrees = dms.values[0].num / dms.values[0].den\n        minutes = dms.values[1].num / dms.values[1].den\n        seconds = dms.values[2].num / dms.values[2].den\n        decimal = degrees + minutes/60 + seconds/3600\n        if ref in ['S', 'W']:\n            decimal *= -1\n        return decimal\n\n    try:\n        lat = get_decimal_from_dms(tags['GPS GPSLatitude'], tags['GPS GPSLatitudeRef'])\n        lon = get_decimal_from_dms(tags['GPS GPSLongitude'], tags['GPS GPSLongitudeRef'])\n        return lat, lon\n    except KeyError:\n        return None, None","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_crack_with_preview(lat, lon, original_img, mask, save_path=\"sut_crack_single_map.html\"):\n    mask_resized = cv2.resize(mask, (original_img.shape[1], original_img.shape[0]))\n    overlay = original_img.copy()\n    overlay[mask_resized == 1] = [255, 0, 0]\n\n    img = PILImage.fromarray(overlay)\n    buffer = BytesIO()\n    img.save(buffer, format=\"PNG\")\n    encoded = base64.b64encode(buffer.getvalue()).decode()\n\n    m = folium.Map(location=[lat, lon], zoom_start=20)\n    html = f'<img src=\"data:image/png;base64,{encoded}\" width=\"300\">'\n    popup = folium.Popup(html, max_width=300)\n    folium.Marker([lat, lon], popup=popup, icon=folium.Icon(color=\"red\")).add_to(m)\n    m.save(save_path)\n    print(f\"✅ Map saved to: {save_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_path = \"/kaggle/input/sut-cracking/SUT-Crack/SUT-Crack/1-Segmentation/Original Image/100.jpg\"\n\ntensor_input, original_img = preprocess_image(img_path)\nmodel = load_model()\npred_mask = predict_crack_mask(model, tensor_input)\nvisualize_result(original_img, pred_mask)\n\nlat, lon = extract_gps_from_exif(img_path)\nif lat and lon:\n    plot_crack_with_preview(lat, lon, original_img, pred_mask)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}